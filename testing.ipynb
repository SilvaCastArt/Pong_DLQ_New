{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:25:20.619202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741321520.637826  248777 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741321520.643485  248777 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 22:25:20.664028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from collections import deque\n",
    "import random\n",
    "from pong_env import PongEnv  # Import our custom Pong environment\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oasc/projvenv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1741321529.938024  248777 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6704 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = PongEnv(render_mode=False)\n",
    "\n",
    "# Build the DQL model\n",
    "model = Sequential([\n",
    "    Dense(24, activation=\"relu\", input_shape=(5,)),\n",
    "    Dense(24, activation=\"relu\"),\n",
    "    Dense(env.action_space.n, activation=\"linear\")\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m75\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,459</span> (9.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,459\u001b[0m (9.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">819</span> (3.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m819\u001b[0m (3.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,640</span> (6.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,640\u001b[0m (6.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_model.keras\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "state = tf.reshape(state, [1, 5])\n",
    "done = False\n",
    "total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-149.20337, -153.59764, -142.40474]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(state, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = deque(maxlen=2000)\n",
    "gamma = 0.95  # Discount factor\n",
    "epsilon = .01  # Exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "mini_batch_size = 32\n",
    "rewards_per_episode = []\n",
    "epsilon_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not done:\n",
    "    if np.random.rand() <= epsilon:\n",
    "        action = env.action_space.sample()  # Explore , go up down or stay\n",
    "    else:\n",
    "        action = np.argmax(model.predict(state, verbose=0))  # Exploit \n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    next_state = np.reshape(next_state, [1, 5])\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "    rewards_per_episode.append(rewards_per_episode)\n",
    "    epsilon_history.append(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007499\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "state = env.reset()\n",
    "time_reset = start_time-datetime.now()\n",
    "# print(f'Reset time: {(start_time-datetime.now()).total_seconds()}')\n",
    "state = np.reshape(state, [1, 5])\n",
    "done = False\n",
    "total_reward = 0\n",
    "start_time = datetime.now()\n",
    "while not done:\n",
    "    if np.random.rand() <= epsilon:\n",
    "        action = env.action_space.sample()  # Explore , go up down or stay\n",
    "    else:\n",
    "        action = np.argmax(model.predict(state, verbose=0))  # Exploit \n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    next_state = np.reshape(next_state, [1, 5])\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "    rewards_per_episode.append(rewards_per_episode)\n",
    "    epsilon_history.append(epsilon)\n",
    "time_episode = datetime.now()-start_time\n",
    "\n",
    "print(time_episode.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(memory[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = random.sample(memory, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([32  5], shape=(2,), dtype=int32)\n",
      "tf.Tensor([32  5], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch_states = tf.convert_to_tensor([exp[0] for exp in batch], dtype=tf.float32)\n",
    "batch_next_states = tf.convert_to_tensor([exp[3] for exp in batch], dtype=tf.float32)\n",
    "# reshape \n",
    "batch_states = tf.squeeze(batch_states,1)\n",
    "batch_next_states =  tf.squeeze(batch_next_states,1)\n",
    "\n",
    "print(tf.shape(batch_states))\n",
    "print(tf.shape(batch_next_states))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch predictions (happens on GPU if available)\n",
    "batch_q_values = model(batch_states, training=False)  # Use model directly\n",
    "batch_next_q_values = model(batch_next_states, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input [[[233.32195   144.24315   102.76389    -2.3125901  -1.9110014]]\n\n [[243.32195    63.302483   35.87884    -2.3125901  -1.9110014]]\n\n [[233.32195    44.80176    20.590832   -2.3125901  -1.9110014]]\n\n [[238.32195   167.36905   121.87391    -2.3125901  -1.9110014]]\n\n [[223.32195   139.61797    98.94189    -2.3125901  -1.9110014]]\n\n [[228.32195    33.23881    11.035825   -2.3125901  -1.9110014]]\n\n [[233.32195   158.11868   114.229904   -2.3125901  -1.9110014]]\n\n [[243.32195   202.05789   150.53893    -2.3125901  -1.9110014]]\n\n [[213.32195   111.86688    76.00987    -2.3125901  -1.9110014]]\n\n [[253.32195   315.37482   244.178      -2.3125901  -1.9110014]]\n\n [[238.32195    70.24026    41.611847   -2.3125901  -1.9110014]]\n\n [[243.32195   208.99567   156.27193    -2.3125901  -1.9110014]]\n\n [[228.32195    47.114353   22.501833   -2.3125901  -1.9110014]]\n\n [[238.32195   151.18091   108.496895   -2.3125901  -1.9110014]]\n\n [[213.32195   118.80465    81.742874   -2.3125901  -1.9110014]]\n\n [[238.32195    42.48917    18.67983    -2.3125901  -1.9110014]]\n\n [[238.32195    91.053566   58.81086    -2.3125901  -1.9110014]]\n\n [[223.32195   128.05501    89.38688    -2.3125901  -1.9110014]]\n\n [[218.32195   116.49206    79.83188    -2.3125901  -1.9110014]]\n\n [[223.32195    30.92622     9.124824   -2.3125901  -1.9110014]]\n\n [[243.32195   255.24747   194.49196    -2.3125901  -1.9110014]]\n\n [[233.32195   169.68164   123.784904   -2.3125901  -1.9110014]]\n\n [[248.32195   257.56006   196.40297    -2.3125901  -1.9110014]]\n\n [[248.32195   252.93489   192.58096    -2.3125901  -1.9110014]]\n\n [[248.32195   278.37338   213.60197    -2.3125901  -1.9110014]]\n\n [[253.32195   285.31116   219.33498    -2.3125901  -1.9110014]]\n\n [[243.32195   266.81042   204.04697    -2.3125901  -1.9110014]]\n\n [[238.32195   181.24458   133.33992    -2.3125901  -1.9110014]]\n\n [[233.32195   171.99423   125.69591    -2.3125901  -1.9110014]]\n\n [[228.32195   141.93056   100.85289    -2.3125901  -1.9110014]]\n\n [[253.32195   232.12157   175.38194    -2.3125901  -1.9110014]]\n\n [[258.32196   273.7482    209.77997    -2.3125901  -1.9110014]]]. Expected shape (None, 5), but input has incompatible shape (32, 1, 5)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 1, 5), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m batch_next_states = tf.convert_to_tensor([exp[\u001b[32m3\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m exp \u001b[38;5;129;01min\u001b[39;00m batch], dtype=tf.float32)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Batch predictions (happens on GPU if available)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m batch_q_values = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use model directly\u001b[39;00m\n\u001b[32m     28\u001b[39m batch_next_q_values = model(batch_next_states, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Compute targets\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projvenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projvenv/lib/python3.12/site-packages/keras/src/models/functional.py:273\u001b[39m, in \u001b[36mFunctional._adjust_input_rank\u001b[39m\u001b[34m(self, flat_inputs)\u001b[39m\n\u001b[32m    271\u001b[39m             adjusted.append(ops.expand_dims(x, axis=-\u001b[32m1\u001b[39m))\n\u001b[32m    272\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    274\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Expected shape \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    275\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    276\u001b[39m     )\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input [[[233.32195   144.24315   102.76389    -2.3125901  -1.9110014]]\n\n [[243.32195    63.302483   35.87884    -2.3125901  -1.9110014]]\n\n [[233.32195    44.80176    20.590832   -2.3125901  -1.9110014]]\n\n [[238.32195   167.36905   121.87391    -2.3125901  -1.9110014]]\n\n [[223.32195   139.61797    98.94189    -2.3125901  -1.9110014]]\n\n [[228.32195    33.23881    11.035825   -2.3125901  -1.9110014]]\n\n [[233.32195   158.11868   114.229904   -2.3125901  -1.9110014]]\n\n [[243.32195   202.05789   150.53893    -2.3125901  -1.9110014]]\n\n [[213.32195   111.86688    76.00987    -2.3125901  -1.9110014]]\n\n [[253.32195   315.37482   244.178      -2.3125901  -1.9110014]]\n\n [[238.32195    70.24026    41.611847   -2.3125901  -1.9110014]]\n\n [[243.32195   208.99567   156.27193    -2.3125901  -1.9110014]]\n\n [[228.32195    47.114353   22.501833   -2.3125901  -1.9110014]]\n\n [[238.32195   151.18091   108.496895   -2.3125901  -1.9110014]]\n\n [[213.32195   118.80465    81.742874   -2.3125901  -1.9110014]]\n\n [[238.32195    42.48917    18.67983    -2.3125901  -1.9110014]]\n\n [[238.32195    91.053566   58.81086    -2.3125901  -1.9110014]]\n\n [[223.32195   128.05501    89.38688    -2.3125901  -1.9110014]]\n\n [[218.32195   116.49206    79.83188    -2.3125901  -1.9110014]]\n\n [[223.32195    30.92622     9.124824   -2.3125901  -1.9110014]]\n\n [[243.32195   255.24747   194.49196    -2.3125901  -1.9110014]]\n\n [[233.32195   169.68164   123.784904   -2.3125901  -1.9110014]]\n\n [[248.32195   257.56006   196.40297    -2.3125901  -1.9110014]]\n\n [[248.32195   252.93489   192.58096    -2.3125901  -1.9110014]]\n\n [[248.32195   278.37338   213.60197    -2.3125901  -1.9110014]]\n\n [[253.32195   285.31116   219.33498    -2.3125901  -1.9110014]]\n\n [[243.32195   266.81042   204.04697    -2.3125901  -1.9110014]]\n\n [[238.32195   181.24458   133.33992    -2.3125901  -1.9110014]]\n\n [[233.32195   171.99423   125.69591    -2.3125901  -1.9110014]]\n\n [[228.32195   141.93056   100.85289    -2.3125901  -1.9110014]]\n\n [[253.32195   232.12157   175.38194    -2.3125901  -1.9110014]]\n\n [[258.32196   273.7482    209.77997    -2.3125901  -1.9110014]]]. Expected shape (None, 5), but input has incompatible shape (32, 1, 5)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 1, 5), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Reduce exploration\n",
    "if epsilon > epsilon_min:\n",
    "    epsilon *= epsilon_decay\n",
    "\n",
    "start_time = datetime.now()\n",
    "# Train with random samples\n",
    "# if len(memory) > 32:\n",
    "#     batch = random.sample(memory, 32)\n",
    "#     for state, action, reward, next_state, done in batch:\n",
    "#         target = reward\n",
    "#         if not done:\n",
    "#             target += gamma * np.amax(model.predict(next_state, verbose=0))\n",
    "#         target_f = model.predict(state, verbose=0)\n",
    "#         target_f[0][action] = target\n",
    "#         model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "# Train with random samples\n",
    "if len(memory) > 32:\n",
    "    batch = random.sample(memory, 32)\n",
    "\n",
    "    # Convert to TensorFlow tensors for better GPU utilization\n",
    "    batch_states = tf.convert_to_tensor([exp[0] for exp in batch], dtype=tf.float32)\n",
    "    batch_next_states = tf.convert_to_tensor([exp[3] for exp in batch], dtype=tf.float32)\n",
    "\n",
    "    # Batch predictions (happens on GPU if available)\n",
    "    batch_q_values = model(batch_states, training=False)  # Use model directly\n",
    "    batch_next_q_values = model(batch_next_states, training=False)\n",
    "\n",
    "    # Compute targets\n",
    "    targets = []\n",
    "    for i, (state, action, reward, next_state, done) in enumerate(batch):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target += gamma * tf.reduce_max(batch_next_q_values[i])  # Tensor operation\n",
    "        target_f = batch_q_values[i].numpy()  # Convert to NumPy to update the action\n",
    "        target_f[action] = target\n",
    "        targets.append(target_f)\n",
    "\n",
    "    # Convert to tensor\n",
    "    targets = tf.convert_to_tensor(targets, dtype=tf.float32)\n",
    "\n",
    "    # Train once on the entire batch\n",
    "    model.fit(batch_states, targets, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pygame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpygame\u001b[49m.event.get():\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.type == pygame.QUIT:\n\u001b[32m      3\u001b[39m         run = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pygame' is not defined"
     ]
    }
   ],
   "source": [
    "for event in pygame.event.get():\n",
    "    if event.type == pygame.QUIT:\n",
    "        run = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
